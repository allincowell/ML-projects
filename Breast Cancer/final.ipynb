{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change this variable to change the maximum depth of the decision tree formed\n",
    "MAX_DEPTH = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split the dataframe into train, cross-validation and test set\n",
    "def train_cv_test_split(df, train_size, cv_size):\n",
    "    n = len(df.index)\n",
    "    \n",
    "    train_size = (int)(n * train_size / 100)\n",
    "    cv_size = (int)(n * cv_size / 100)\n",
    "    \n",
    "    indices = df.index.tolist()\n",
    "    train_indices = random.sample(population = indices, k = train_size)\n",
    "    \n",
    "    train_set = df.loc[train_indices]\n",
    "    df = df.drop(train_indices)\n",
    "    \n",
    "    indices = df.index.tolist()\n",
    "    cv_indices = random.sample(population = indices, k = cv_size)\n",
    "    \n",
    "    cv_set = df.loc[cv_indices]\n",
    "    test_set = df.drop(cv_indices)\n",
    "    \n",
    "    return train_set, cv_set, test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for building the decision tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to check if all the data points belong to a single class\n",
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to return the majority class in a dataframe\n",
    "def classify_data(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts = True)\n",
    "\n",
    "    index = counts_unique_classes.argmax()\n",
    "    classification = unique_classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get the all the unique values of all the attributes as potential splits of the dataset\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        \n",
    "        potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to split a dataset based on a given value of a given attribute\n",
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "    data_below = data[split_column_values == split_value]\n",
    "    data_above = data[split_column_values != split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to determine entropy of the dataset\n",
    "def calculate_entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts = True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate the total entropy of the split dataset\n",
    "def calculate_overall_entropy(data_below, data_above):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "\n",
    "    overall_entropy =  (p_data_below * calculate_entropy(data_below) \n",
    "                      + p_data_above * calculate_entropy(data_above))\n",
    "    \n",
    "    return overall_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to determine best attribute and its value for splitting the dataset \n",
    "def determine_best_split(data, potential_splits):\n",
    "    \n",
    "    overall_entropy = 9999\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            current_overall_entropy = calculate_overall_entropy(data_below, data_above)\n",
    "\n",
    "            if current_overall_entropy <= overall_entropy:\n",
    "                overall_entropy = current_overall_entropy\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to build decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, counter = 0, max_depth = 5):\n",
    "    \n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        data = df.values\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    \n",
    "    # base cases\n",
    "    if (check_purity(data)) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "\n",
    "    \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "\n",
    "        # helper functions \n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        # check for empty data\n",
    "        if len(data_below) == 0 or len(data_above) == 0:\n",
    "            classification = classify_data(data)\n",
    "            return classification\n",
    "        \n",
    "        # determine question\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        \n",
    "        question = \"{} = {}\".format(feature_name, split_value)\n",
    "        \n",
    "        # instantiate sub-tree\n",
    "        sub_tree = {question: []}\n",
    "        \n",
    "        # find answers (recursion)\n",
    "        yes_answer = decision_tree_algorithm(data_below, counter, max_depth)\n",
    "        no_answer = decision_tree_algorithm(data_above, counter, max_depth)\n",
    "        \n",
    "        # If the answers are the same, then there is no point in asking the qestion.\n",
    "        # This could happen when the data is classified even though it is not pure\n",
    "        # yet (min_samples or max_depth base case).\n",
    "        \n",
    "        if yes_answer == no_answer:\n",
    "            sub_tree = yes_answer\n",
    "        else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to classify a single new example using a given decision tree\n",
    "def classify_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    if str(example[feature_name]) == value:\n",
    "        answer = tree[question][0]\n",
    "    else:\n",
    "        answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classify_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to calculate accuracy of tree on the given test set\n",
    "def calculate_accuracy(df, tree):\n",
    "    \n",
    "    if(isinstance(tree, str)):\n",
    "        total_examples = df.shape[0]\n",
    "        matching_examples = df[df[\"label\"] == tree][\"label\"].shape[0]\n",
    "        accuracy = matching_examples / total_examples\n",
    "    else:    \n",
    "        df[\"classification\"] = df.apply(classify_example, axis = 1, args = (tree,))\n",
    "        df[\"classification_correct\"] = df[\"classification\"] == df[\"label\"]\n",
    "\n",
    "        accuracy = df[\"classification_correct\"].mean()\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions to post-prune a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to classify a single new example using a given decision tree\n",
    "def predict_example(example, tree):\n",
    "    \n",
    "    # tree is just a root node\n",
    "    if not isinstance(tree, dict):\n",
    "        return tree\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    \n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return predict_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to classify a test set based on the given decision tree\n",
    "def make_predictions(df, tree):\n",
    "    \n",
    "    if len(df) != 0:\n",
    "        predictions = df.apply(predict_example, args = (tree,), axis = 1)\n",
    "    else:\n",
    "        predictions = pd.Series([], dtype = pd.StringDtype())\n",
    "        \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, question):\n",
    "    feature, comparison_operator, value = question.split()\n",
    "\n",
    "    df_yes = df[df[feature].astype(str) == value]\n",
    "    df_no  = df[df[feature].astype(str) != value]\n",
    "    \n",
    "    return df_yes, df_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_leaf(df_train):\n",
    "    return df_train.label.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_errors(df_val, tree):\n",
    "    predictions = make_predictions(df_val, tree)\n",
    "    actual_values = df_val.label\n",
    "    \n",
    "    return sum(predictions != actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_result(tree, df_train, df_val):\n",
    "    \n",
    "    leaf = determine_leaf(df_train)\n",
    "    errors_leaf = determine_errors(df_val, leaf)\n",
    "    errors_decision_node = determine_errors(df_val, tree)\n",
    "\n",
    "    if errors_leaf <= errors_decision_node:\n",
    "        return leaf\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to post-prune a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to post-prune a given tree using given train and cross validation set\n",
    "def post_pruning(tree, df_train, df_val):\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    yes_answer, no_answer = tree[question]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(yes_answer, dict) and not isinstance(no_answer, dict):\n",
    "        return pruning_result(tree, df_train, df_val)\n",
    "        \n",
    "    # recursive part\n",
    "    else:\n",
    "        df_train_yes, df_train_no = filter_df(df_train, question)\n",
    "        df_val_yes, df_val_no = filter_df(df_val, question)\n",
    "        \n",
    "        if isinstance(yes_answer, dict):\n",
    "            yes_answer = post_pruning(yes_answer, df_train_yes, df_val_yes)\n",
    "            \n",
    "        if isinstance(no_answer, dict):\n",
    "            no_answer = post_pruning(no_answer, df_train_no, df_val_no)\n",
    "        \n",
    "        tree = {question: [yes_answer, no_answer]}\n",
    "    \n",
    "        return pruning_result(tree, df_train, df_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"breast-cancer.data\", names = ['Class','age','menopause','tumor_size','inv_nodes','node_caps','deg_malig','breast','breast_quad','irradiat'])\n",
    "df[\"label\"] = df.Class\n",
    "df = df.drop([\"Class\"], axis = 1)\n",
    "\n",
    "mode_node_caps = df.node_caps.mode()[0]\n",
    "mode_breast_quad = df.breast_quad.mode()[0]\n",
    "\n",
    "df['node_caps'] = df['node_caps'].replace(['?'], mode_node_caps)\n",
    "df['breast_quad'] = df['breast_quad'].replace(['?'], mode_breast_quad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating 10 random 60/20/20 splits on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, cv_set, test_set = [], [], []\n",
    "\n",
    "for i in range(10):\n",
    "    train, cv, test = train_cv_test_split(df, 60, 20)\n",
    "    train_set.append(train)\n",
    "    cv_set.append(cv)\n",
    "    test_set.append(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building tree and calculating accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of split no.  1  =  0.7931034482758621\n",
      "Accuracy of split no.  2  =  0.7241379310344828\n",
      "Accuracy of split no.  3  =  0.7586206896551724\n",
      "Accuracy of split no.  4  =  0.603448275862069\n",
      "Accuracy of split no.  5  =  0.7931034482758621\n",
      "Accuracy of split no.  6  =  0.8275862068965517\n",
      "Accuracy of split no.  7  =  0.6896551724137931\n",
      "Accuracy of split no.  8  =  0.7413793103448276\n",
      "Accuracy of split no.  9  =  0.6379310344827587\n",
      "Accuracy of split no.  10  =  0.7931034482758621\n"
     ]
    }
   ],
   "source": [
    "# evaluating average accuracy over 10 random 60/20/20 splits\n",
    "mean_accuracy = 0.0\n",
    "best_accuracy = 0.0\n",
    "best_accuracy_index = 0\n",
    "\n",
    "for i in range(10):\n",
    "    if MAX_DEPTH != -1:\n",
    "        tree = decision_tree_algorithm(train_set[i], max_depth = MAX_DEPTH)\n",
    "    else:\n",
    "        tree = decision_tree_algorithm(train_set[i], max_depth = 10000000)\n",
    "    accuracy = calculate_accuracy(test_set[i], tree)\n",
    "    \n",
    "    if(best_accuracy <= accuracy):\n",
    "        best_accuracy = accuracy\n",
    "        best_accuracy_index = i\n",
    "    \n",
    "    print(\"Accuracy of split no. \", i + 1, \" = \", accuracy)\n",
    "    mean_accuracy += accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average accuracy =  0.7362068965517242\n"
     ]
    }
   ],
   "source": [
    "print(\"Average accuracy = \", mean_accuracy / 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best depth limit calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "depths = range(1, 16)\n",
    "accuracies = []\n",
    "\n",
    "for depth in depths:\n",
    "    tree = decision_tree_algorithm(train_set[best_accuracy_index], max_depth = depth)\n",
    "    \n",
    "    accuracy = calculate_accuracy(test_set[best_accuracy_index], tree)\n",
    "    accuracies.append(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1eb83ad9cd0>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting graph for accuracy v/s depth to find best possible split\n",
    "plt.xlabel(\"depths\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.title(\"accuracy v/s depth\")\n",
    "plt.plot(depths, accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-pruning tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding the depth at which we have maximum accuracy\n",
    "optimal_accuracy = 0;\n",
    "optimal_depth = 0;\n",
    "\n",
    "for depth in depths:\n",
    "    if(accuracies[depth - 1] > optimal_accuracy):\n",
    "        optimal_accuracy = accuracies[depth - 1]\n",
    "        optimal_depth = depth\n",
    "        \n",
    "# tree obtained from part 2 having maximum accuracy in the graph is evaluated here\n",
    "tree = decision_tree_algorithm(train_set[best_accuracy_index], max_depth = optimal_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tree without pruning\n",
      "{'deg_malig = 3': [{'inv_nodes = 0-2': [{'breast_quad = right_up': ['recurrence-events',\n",
      "                                                                    'no-recurrence-events']},\n",
      "                                        'recurrence-events']},\n",
      "                   'no-recurrence-events']}\n"
     ]
    }
   ],
   "source": [
    "print(\"The tree without pruning\")\n",
    "pprint(tree, width = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without pruning: 0.8448275862068966\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy without pruning:\", calculate_accuracy(test_set[best_accuracy_index], tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_pruned = post_pruning(tree, train_set[best_accuracy_index], cv_set[best_accuracy_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final pruned tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with pruning: 0.8275862068965517\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy with pruning:\", calculate_accuracy(test_set[best_accuracy_index], tree_pruned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final decision tree is\n",
      "{'deg_malig = 3': [{'inv_nodes = 0-2': ['no-recurrence-events',\n",
      "                                        'recurrence-events']},\n",
      "                   'no-recurrence-events']}\n"
     ]
    }
   ],
   "source": [
    "print(\"The final decision tree is\")\n",
    "pprint(tree_pruned, width = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
